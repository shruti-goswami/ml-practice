# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N7DUUj7eZ-BeYlwnrY8ycTRPb24NQeus

This notebook predicts the student scores based on the number of hours studied. The source of the dataset is from kaggle : https://www.kaggle.com/datasets/samira1992/student-scores-simple-dataset/data

The implementation is from scratch and then the same is compared with sklearn library's prediction.
"""

## Import required modules
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

## Load dataset
df = pd.read_csv('Salary_Data.csv')
df.head()
X = np.array(df['YearsExperience'])
y = np.array(df['Salary'])

"""**Linear Regression from scratch**"""

## Initalise parameters
m, c = 0, 0
lr = 0.002
## Number of iterations can be decided based when our cost function value starts becoming constant.
epochs = 10000
n = len(X)

# Gradient descent
for i in range(epochs) :
  y_pred = m*X + c
  cost = (1/n)*sum([value**2 for value in (y-y_pred)])
  dm = (-2/n) * sum(X * (y-y_pred))
  dc = (-2/n) * sum(y - y_pred)
  m -= lr * dm
  c -= lr * dc
  print ("m {}, c {}, cost {}, iteration {}".format(m,c,cost, i))

print(f"From Scratch → m={m:.3f}, c={c:.3f}")

## Calculate with sklearn
model = LinearRegression()
model.fit(df[['YearsExperience']], df['Salary'])
print(f"From sklearn → m={model.coef_[0]:.3f}, c={model.intercept_:.3f}")
y_pred_sklearn = model.predict(df[['YearsExperience']])

## Comparing with sklearn
print("MSE (scratch):", mean_squared_error(y, m*X + c))
print("MSE (sklearn):", mean_squared_error(y, y_pred_sklearn))

import matplotlib.pyplot as plt
plt.scatter(X, y, color="blue")
plt.plot(X, m*X + c, color="red", label="Scratch")
plt.plot(X, y_pred_sklearn, color="green", linestyle="--", label="Sklearn")
plt.legend()
plt.show()